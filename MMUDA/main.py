import argparse
import torch
import numpy as np
import random
import os
import pandas as pd
from trainer import Trainer
import gc
from itertools import product
from datetime import datetime

def main():
    seed = 10
    cuda_id = 1
    dataset_list = ['SLEEPEDF', 'HMC', 'ISRUC', 'DCSM','P2018'] 

    if cuda_id >= torch.cuda.device_count():
        raise ValueError(f"âŒ æ— æ•ˆGPUç¼–å·ã€‚ä½ åªæœ‰ {torch.cuda.device_count()} å¼ GPU,ä½†ä½ è¯•å›¾ä½¿ç”¨ cuda:{cuda_id}")

    torch.cuda.set_device(cuda_id)
    device = torch.device(f"cuda:{cuda_id}" if torch.cuda.is_available() else "cpu")
    print(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name(cuda_id)} (cuda:{cuda_id})")
    setup_seed(seed)

    # è¶…å‚æ•°æœç´¢ç©ºé—´
    lmmd_weights = [0.01]
    contrastive_weights = [0.1]
    ae_weights = [0.01]
    dropouts = [0.1]
    lrs = [5e-3]

    # âœ… ç»Ÿä¸€ç»“æœ CSV æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_path = f"results_all_datasets_runs_{timestamp}.csv"
    write_header = True

    all_results_across_datasets = []

    for dataset in dataset_list:
        print(f"\nğŸ“‚ å¼€å§‹å¤„ç†æ•°æ®é›†: {dataset}")
        dataset_results = []

        for run_id in range(2):  # å¯è®¾ç½®ä¸ºå¤šè½® run
            print(f"\nğŸš€ å¼€å§‹ç¬¬ {run_id + 1} è½®è°ƒå‚ for {dataset}")

            for lmmd_weight, contrastive_weight, ae_weight, dropout, lr in product(
                lmmd_weights, contrastive_weights, ae_weights, dropouts, lrs
            ):
                print(f"\nğŸ” Run {run_id + 1} | lmmd={lmmd_weight}, contrastive={contrastive_weight}, ae_weight={ae_weight}, dropout={dropout}, lr={lr}")

                # æ„é€ å‚æ•°
                params = argparse.Namespace(
                    target_domains=[dataset],
                    cuda=cuda_id,
                    epochs=70,
                    batch_size=64,
                    num_of_classes=5,
                    lr=lr,
                    clip_value=1,
                    dropout=dropout,
                    loss_function='CrossEntropyLoss',
                    datasets_dir='data',
                    model_dir='modelsEDF',
                    num_workers=16,
                    label_smoothing=0.1,
                    latent_dim=512,
                    encoder_output_dim=512,
                    mmd_weight=lmmd_weight,
                    contrastive_weight=contrastive_weight,
                    ae_weight=ae_weight
                )

                trainer = Trainer(params, device)
                test_acc, test_f1 = trainer.train()

                result_entry = {
                    'dataset': dataset,
                    'run': run_id + 1,
                    'lmmd_weight': lmmd_weight,
                    'contrastive_weight': contrastive_weight,
                    'ae_weight': ae_weight,
                    'dropout': dropout,
                    'lr': lr,
                    'acc': test_acc,
                    'f1': test_f1
                }

                dataset_results.append(result_entry)
                all_results_across_datasets.append(result_entry)

                # âœ… å®æ—¶è¿½åŠ åˆ°ç»Ÿä¸€ CSV æ–‡ä»¶
                df_row = pd.DataFrame([result_entry])
                df_row.to_csv(csv_path, mode='a', index=False, header=write_header)
                write_header = False

                torch.cuda.empty_cache()
                gc.collect()

        print(f"\nğŸ“„ {dataset} çš„ç»“æœå·²è¿½åŠ ä¿å­˜åˆ°ï¼š{csv_path}")

        # åˆ†ææ¯ä¸ªæ•°æ®é›†çš„æœ€ä½³ç»„åˆ
        df_dataset = pd.DataFrame(dataset_results)
        best_group = (
            df_dataset.groupby(['lmmd_weight', 'contrastive_weight', 'ae_weight', 'dropout', 'lr'])[['acc', 'f1']]
            .mean()
            .sort_values('f1', ascending=False)
            .reset_index()
        )

        print(f"\nğŸ† {dataset} æœ€ä½³è¶…å‚æ•°ç»„åˆï¼ˆæŒ‰å¹³å‡ F1 é™åºï¼‰:")
        print(best_group.head(5))

    # âœ… æ‰€æœ‰æ•°æ®é›†çš„ç»“æœåˆ†æï¼ˆå…¨å±€æœ€ä½³ï¼‰
    df_all = pd.DataFrame(all_results_across_datasets)
    print("\nğŸ“Š æ‰€æœ‰æ•°æ®é›†æ•´ä½“æœ€ä½³è¶…å‚æ•°ç»„åˆï¼ˆæŒ‰å¹³å‡ F1 æ’åºï¼‰:")
    global_best = (
        df_all.groupby(['lmmd_weight', 'contrastive_weight', 'ae_weight', 'dropout', 'lr'])[['acc', 'f1']]
        .mean()
        .sort_values('f1', ascending=False)
        .reset_index()
    )
    print(global_best.head(5))

def setup_seed(seed):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True

if __name__ == '__main__':
    main()
